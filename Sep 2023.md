# T2I
- Any-Size-Diffusion: Toward Efficient Text-Driven Synthesis for Any-Size HD Images[[paper]](http://arxiv.org/pdf/2308.16582v1)
- VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual Grounders[[paper]](http://arxiv.org/pdf/2309.01141v1)
- RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model[[paper]](http://arxiv.org/pdf/2309.00810v1)
- SyncDreamer: Generating Multiview-consistent Images from a Single-view Image[[paper]](http://arxiv.org/pdf/2309.03453v1)
- PAI-Diffusion: Constructing and Serving a Family of Open Chinese Diffusion Models for Text-to-image Synthesis on the Cloud[[paper]](http://arxiv.org/pdf/2309.05534v1)[[project]]((https://huggingface.co/alibaba-pai))
- InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation[[paper]](http://arxiv.org/pdf/2309.06380v1)[[project]](https://github.com/gnobitab/InstaFlow)
-  PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion Models[[paper]](http://arxiv.org/pdf/2309.05793v1)[[project]](https://photoverse2d.github.io/)
- Unbiased Face Synthesis With Diffusion Models: Are We There Yet?[[paper]](http://arxiv.org/pdf/2309.07277v1)
- CARTOONDIFF: TRAINING-FREE CARTOON IMAGE GENERATION WITH DIFFUSION TRANSFORMER MODELS[[paper]](http://arxiv.org/pdf/2309.08251v1)[[project]](https://cartoondiff.github.io/)
- Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation[[paper]](http://arxiv.org/pdf/2309.14859v1)[[project]](https://github.com/KohakuBlueleaf/LyCORIS)
- Text-image guided Diffusion Model for generating Deepfake celebrity interactions[[paper]](https://arxiv.org/pdf/2309.14751v1.pdf)
# T2V
- VideoGen: A Reference-Guided Latent Diffusion Approach for High Definition Text-to-Video Generation[[paper]](http://arxiv.org/pdf/2309.00398v1)[[project???]]
- MagicProp: Diffusion-based Video Editing via Motion-aware Appearance Propagation[[paper]](http://arxiv.org/pdf/2309.00908v1)
- Reuse and Diffuse: Iterative Denoising for Text-to-Video Generation[[paper]](http://arxiv.org/pdf/2309.03549v1)[[project]](https://anonymous0x233.github.io/ReuseAndDiffuse/)
- LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models[[paper]](https://arxiv.org/pdf/2309.15103v1.pdf)[[project]](https://vchitect.github.io/LaVie-project/)
- SHOW-1: MARRYING PIXEL AND LATENT DIFFUSION MODELS FOR TEXT-TO-VIDEO GENERATION[[paper]](https://arxiv.org/pdf/2309.15818v1.pdf)[[project]](https://showlab.github.io/Show-1/)