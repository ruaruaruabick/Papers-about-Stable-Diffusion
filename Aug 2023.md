# T2I
- DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation，[paper](http://arxiv.org/pdf/2307.16687v1)
- MobileVidFactory: Automatic Diffusion-Based Social Media Video Generation for Mobile Devices from Text，[paper](http://arxiv.org/pdf/2307.16371v1)
- ImageBrush: Learning Visual In-Context Instructionsfor Exemplar-Based Image Manipulation，[paper](https://arxiv.org/pdf/2308.00906v1.pdf)
- Patched Denoising Diffusion Models For High-Resolution Image Synthesis, [paper](https://arxiv.org/pdf/2308.01316v1.pdf)
- Painterly Image Harmonization using Diffusion Model, [paper](https://arxiv.org/pdf/2308.02228v1.pdf)
- DiffSynth: Latent In-Iteration Deflickering for Realistic Video Synthesis, [paper](http://arxiv.org/pdf/2308.03463v1)
- Sketch and Text Guided Diffusion Model for Colored Point Cloud Generation[paper](https://arxiv.org/pdf/2308.02874v1.pdf)
- LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation[paper](http://arxiv.org/pdf/2308.05095v1)
- Dancing Avatar: Pose and Text-Guided Human Motion Videos Synthesis with Image Diffusion Model[paper](http://arxiv.org/pdf/2308.07749v1)
- SGDiff: A Style Guided Diffusion Model for Fashion Synthesis[paper](https://arxiv.org/pdf/2308.07605v1.pdf)
- IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models[paper](https://arxiv.org/pdf/2308.06721v1.pdf)
- TeCH: Text-guided Reconstruction of Lifelike Clothed Humans[paper](http://arxiv.org/pdf/2308.08545v1)
- AltDiffusion: A Multilingual Text-to-Image Diffusion Model[paper](http://arxiv.org/pdf/2308.09991v1)
- ControlCom: Controllable Image Composition using Diffusion Model[paper](http://arxiv.org/pdf/2308.10040v1)
- DiffCloth: Diffusion Based Garment Synthesis and Manipulation via Structural Cross-modal Semantic Alignment[paper](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://arxiv.org/pdf/2308.11206v1.pdf)
- IT3D: Improved Text-to-3D Generation with Explicit View Synthesis[paper](http://arxiv.org/pdf/2308.11473v1)
- High-quality Image Dehazing with Diffusion Model[paper](http://arxiv.org/pdf/2308.11949v1)
- Dense Text-to-Image Generation with Attention Modulation[paper](http://arxiv.org/pdf/2308.12964v1)
- A Survey of Diffusion Based Image Generation Models: Issues and Their Solutions[[paper]](http://arxiv.org/pdf/2308.13142v1)
- Total Selfie: Generating Full-Body Selfies[[paper]](http://arxiv.org/pdf/2308.14740v1)[[project]](https://homes.cs.washington.edu/~boweiche/project_page/totalselfie/)
# T2V
- Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models[paper](http://arxiv.org/pdf/2308.13812v1)